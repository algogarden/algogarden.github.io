<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>http://0.0.0.0:4000</link>
    <atom:link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/rss+xml" />
    <description></description>
    <language>en-us</language>
    <pubDate>Tue, 24 Sep 2019 06:15:08 -0500</pubDate>
    <lastBuildDate>Tue, 24 Sep 2019 06:15:08 -0500</lastBuildDate>

    
      <item>
        <title>Tối ưu hóa cache với LFU và LRU</title>
        <link>http://0.0.0.0:4000/work/2019/07/24/implement-cache-lru-lfu.html</link>
        <pubDate>Wed, 24 Jul 2019 00:00:00 -0500</pubDate>
        <author></author>
        <description>&lt;p&gt;Tối ưu hóa luôn là vấn đề được quan tâm hàng đầu trong nhiều lĩnh vực. Bởi vì tài nguyên chúng ta đang sử dụng có giới hạn, vậy nên con người luôn tìm cách giảm thiếu chi phí và thời gian tới mức tối thiểu.&lt;/p&gt;

&lt;p&gt;Trong lập trình cũng vậy, chúng ta cũng phải đối mặt với vấn đề tối ưu hóa thường xuyên. Thực tế, câu hỏi &lt;b&gt;“Làm sao để tối ưu ?”&lt;/b&gt; được đặt ra nhiều hơn khi đi làm so với khi còn ngồi trên ghế nhà trường.&lt;/p&gt;

&lt;p&gt;Khi còn ở trường, vấn đề tối ưu đầu tiên tôi gặp phải là &lt;b&gt; tối ưu thuật toán fibonaci&lt;/b&gt;. Nếu sử dụng cách đệ quy thông thường thì O(n) sẽ là 2&lt;sup&gt;n&lt;/sup&gt;. Để tối ưu bài toán, có thể cân nhắc đến kĩ thuật &lt;b&gt;memorization&lt;/b&gt; giảm chi phí cho bài toán xuống còn O(n) = n. Bản chất đằng sau của thuật toán này là lưu lại các giá trị đã tính trước để phục vụ cho sau này.&lt;/p&gt;

&lt;p&gt;Khi đi làm, để tối ưu trải nghiệm của người dùng sử dụng website thì tôi sử dụng cache. Đây là một hệ thống quan trọng để cải thiện hiệu năng của ứng dụng thông qua việc cho phép truy cập và trích xuất dữ liệu nhanh hơn. Mặc dù có khá nhiều ứng dụng cho cache và phụ thuộc vào tính chất công việc, nhưng ý tưởng đằng sau đó khá đơn giản.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p style=&quot;font-size:16px;text-align:center&quot;&gt;Lưu trữ những dữ liệu cần thiết hoặc được sử dụng nhiều trong một &quot;kho chứa&quot; để lần lấy ra tiếp theo sẽ nhanh hơn.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Trong thực tế, cache không nhanh hơn thanh ghi (register) nhưng nhanh hơn nhiều khi so với bộ nhớ chính ( main memory). Để truy cập dữ liệu từ bộ nhớ chính sẽ tốn nhiều thời gian, vậy nên để giảm quá trình này một vùng nhớ đặc biệt trong CPU sẽ được dành riêng chứa một lượng nhỏ dữ liệu cần thiết. Khi một tiến trình muốn tiếp cận lượng dữ liệu trên, đầu tiên nó sẽ kiểm tra trong cache, nếu tìm thấy thì lấy ra và chế biến, nếu không nó mới đi tiếp tới bộ nhớ chính.&lt;/p&gt;

&lt;p&gt;Cache phải tuân thủ theo &lt;b&gt;replacement policy&lt;/b&gt; khi dung lượng vượt quá giới hạn:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;-  Quyết định được dữ liệu nào cần loại bỏ.&lt;/li&gt;
    &lt;li&gt;-  Tối thiếu được số lượng cache misses. &lt;/li&gt;
    &lt;li&gt;-  Chi phí thấp. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Có rất nhiều thuật toán implement cache, trong đó có 2 thuật toán đơn giản là &lt;b&gt;Least Recently Used&lt;/b&gt; và&lt;b&gt; Least Frequently Used&lt;/b&gt; được sử dụng rộng rãi. Và cũng là 2 thuật toán tôi muốn giới thiệu trong bài viết này.&lt;/p&gt;

&lt;h3&gt;&lt;b&gt; Least Recently Used &lt;/b&gt;&lt;/h3&gt;
&lt;p&gt;Thuật toán này lấy thời gian lần cuối sử dụng object để quyết định có loại bỏ hay không?. Cụ thể, nó sẽ xóa object có thời điểm được sử dụng gần nhất cách thời điểm hiện tại xa nhất khỏi bộ nhớ khi bộ chứa đạt tới giới hạn. Một object vừa được truy cập sẽ được đẩy vào cache hoặc ghi đè thời gian sử dụng nếu đã nằm sẵn trong cache.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p style=&quot;font-size:16px;text-align:center&quot;&gt;Ví dụ: Bạn có một tủ chật kín quần áo và cần bỏ đi vài cái để sắm quần áo mới. Lúc này bạn sẽ loại đi những bộ quần áo mà lần gần nhất bạn mặc cách đây lâu nhất. Để giả định này đúng, do uống trà sữa quá nhiều nên tăng cân, bạn không thể mặc những bộ quần áo cũ mặc dù rất đẹp. Lần cuối mặc nó là lúc chưa tăng cân.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5&gt; &lt;u&gt;Phân tích cấu trúc dữ liệu:&lt;/u&gt;&lt;/h5&gt;

&lt;p&gt;&lt;br /&gt;
Để implement được LRU, cần có một data structure đảm bảo được:&lt;/p&gt;

&lt;table style=&quot;border-collapse: collapse;&quot;&gt;
  &lt;tr&gt;
    &lt;th style=&quot;border: 1px solid black;  text-align: left; padding:5px; width:50%&quot;&gt;Yêu cầu&lt;/th&gt;
    &lt;th style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;Data structure&lt;/th&gt;
    &lt;th style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;Chi phí độ phức tạp&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px; width:50%&quot;&gt;Tìm kiếm&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;HashMap hoặc HashTable.&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;O(1)&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px; width:50%&quot;&gt;Thêm mới một object&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;Static array, linked list, Hashmap ( HashTable ) với tỉ lệ collision thấp. &lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;O(1)&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td rowspan=&quot;2&quot; style=&quot;border: 1px solid black;  text-align: left; padding:5px; width:50%&quot;&gt;Xóa object gần nhất sử dụng cách hiện tại xa nhất.&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;Double Linked list được sắp xếp theo thời gian gần nhất sử dụng tăng dần.&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;O(1)&lt;/td&gt;
  &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;Hàng đợi ưu tiên ( Priority queue). Cụ thể là Min-heap với key là thời gian gần nhất truy cập của object. &lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;O(logn)&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td rowspan=&quot;2&quot; style=&quot;border: 1px solid black;  text-align: left; padding:5px; width:50%&quot;&gt;Khi một object đã có trong cache được truy cập thì sẽ ghi đè thời điểm hiện tại vào cache. Đồng thời vẫn đảm bảo vị trí các object theo chiều tăng dần thời gian.&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;Sử dụng HashMap(HashTable) cho tìm kiếm O(1). Với double linked list thì xóa O(1). Sau đó thêm mới object với thời gian hiện tại là O(1).  &lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;O(1)&lt;/td&gt;
  &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;Min-heap như trên. Để đảm bảo tính đúng của Min_heap thì sử dụng heapify cho ta O(logn). &lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;O(logn)&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;&lt;br /&gt;
Với bảng phân tích như trên chúng ta dễ dàng chọn được cấu trúc dữ liệu thích hợp và tốt nhất để xây dựng LRU là : &lt;b&gt;HashMap&lt;/b&gt; và&lt;b&gt; Double Linked List&lt;/b&gt;.&lt;/p&gt;

&lt;h5&gt; &lt;u&gt;Implement LRU:&lt;/u&gt;&lt;/h5&gt;
&lt;p&gt;&lt;b&gt;LRU node &lt;/b&gt;chứa dữ liệu, thời gian sử dụng và 2 con trỏ tới các node khác.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Hash Map&lt;/b&gt; giữ key và LRU node tương ứng.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Double Linked List&lt;/b&gt; lưu head là node chứa dữ liệu có thời gian sử dụng cuối cùng xa nhất. Ngược lại, tail sẽ lưu node được sử dụng gần đầy nhất.&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;
 &lt;img src=&quot;/assets/img/blog/content/lru-1.png&quot; alt=&quot;Complicated process&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h5&gt; &lt;u&gt;Coding LRU:&lt;/u&gt;&lt;/h5&gt;
&lt;p&gt;&lt;b&gt;LRU Node&lt;/b&gt;
&lt;br /&gt;
 &lt;img src=&quot;/assets/img/blog/content/lru-code1.png&quot; alt=&quot;Complicated process&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;b&gt;Double Linked List&lt;/b&gt;
&lt;br /&gt;
 &lt;img src=&quot;/assets/img/blog/content/lru-code2.png&quot; alt=&quot;Complicated process&quot; /&gt;
&lt;img src=&quot;/assets/img/blog/content/lru-code3.PNG&quot; alt=&quot;Complicated process&quot; /&gt;&lt;/p&gt;

&lt;h5&gt; &lt;u&gt;Đánh giá với implement bằng priority heap:&lt;/u&gt;&lt;/h5&gt;
&lt;p&gt;Sử dụng thư viện &lt;b&gt;cProfile&lt;/b&gt; để đánh giá hiệu năng.&lt;br /&gt;
Cache chứa được 2048 phần tử, giá trị random từ 1 đến 5000, 100000 hành động put và 1000 hành động get.
&lt;br /&gt;
&lt;img src=&quot;/assets/img/blog/content/lru-compare.PNG&quot; alt=&quot;Complicated process&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;u&gt;HashTable + Double Linked List:&lt;/u&gt;
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/assets/img/blog/content/lru-compare1.PNG&quot; alt=&quot;Complicated process&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;u&gt;Priority Heap:&lt;/u&gt;
&lt;br /&gt;
&lt;br /&gt;
&lt;img src=&quot;/assets/img/blog/content/lru-compare2.PNG&quot; alt=&quot;Complicated process&quot; /&gt;&lt;/p&gt;
&lt;p&gt; Bỏ thời gian thực hiện random một giá trị cho phần test và các hàm khởi tạo khác. Để khách quan, chúng ta không xét thời gian của hàm tìm kiếm vì với heap sẽ có O(n) ( vì giá trị tìm kiếm không phải là giá trị xây dựng heap ), mà chỉ so sánh thời gian thực hiện hàm xóa và duy trì tính đúng của heap.&lt;/p&gt;
&lt;table style=&quot;border-collapse: collapse;&quot;&gt;
  &lt;tr&gt;
    &lt;th style=&quot;border: 1px solid black;  text-align: left; padding:5px; width:50%&quot;&gt;Action&lt;/th&gt;
    &lt;th style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;Double Linked List + Hash map&lt;/th&gt;
    &lt;th style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;Priority Heap&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px; width:50%&quot;&gt;removeNode + Heapify(for Heap)&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;0.21&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;3.216&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px; width:50%&quot;&gt;updateNode + Heapify(for Heap)&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;1.24 &lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;0.639&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px; width:50%&quot;&gt;addNode&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;0.02&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;0.008&lt;/td&gt;
  &lt;/tr&gt;
   &lt;tr&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px; width:50%&quot;&gt;Heapify&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;0&lt;/td&gt;
    &lt;td style=&quot;border: 1px solid black;  text-align: left; padding:5px;&quot;&gt;3.670&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;&lt;br /&gt;
Heapify có độc phức tạp là O(logn). Vậy nên khi so sánh update và remove với HashMap + Double Linked List có O(1) thì thời gian chênh nhau khá lớn. Chỉ tính riêng Heapify đã chiếm thời gian nhiều nhất. Ở bài tiếp theo tôi sẽ giới thiệu &lt;b&gt; Least Frequently Used&lt;/b&gt;.&lt;/p&gt;
</description>
      </item>
    
      <item>
        <title>Tâm sự cùng mưa</title>
        <link>http://0.0.0.0:4000/life/2019/05/01/tam-su-cung-mua.html</link>
        <pubDate>Wed, 01 May 2019 00:00:00 -0500</pubDate>
        <author></author>
        <description>&lt;p&gt;Tại thời điểm bản tình ca ánh trăng chuẩn bị nhường chỗ cho những tia nắng nhộn nhịp, tôi gặp lại người bạn cũ của mình. Mưa . Cơn mưa không báo trước này rả rích cuốn trôi đi phần nào cái oi bức của những ngày hạ Sài Gòn. Mưa không to lắm, nhẹ nhàng rải đều trong không trung. Có lẽ đúng khi nói mưa là sự kết nối đến tâm tư người ngắm mưa. Bất giác từ lúc nào bàn tay tôi đã đưa ra đón lấy những giọt mưa.
&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;- Mưa à, phải sống dưới cái nắng dài hơi và khắc nghiệt, tôi mới thấy trân trọng em. Tôi không nhận mình là người hoàn toàn yêu mưa, nhưng cũng phải yêu đến 8 9 phần. Mưa thì mát nhưng tát vào mặt không trượt phát nào thì lại rất đau vậy nên yêu em tôi không thể &quot;yêu cả đường đi lối về.&quot; &lt;/p&gt;

&lt;p&gt;- Có biết bao nhiêu người nói yêu mưa trong khi mở to dù mỗi khi ta đến và ngươi cũng không ngoại lệ. Ta biết ngươi cũng hơn hai chục năm rồi chỉ toàn nghe ngươi nói &quot; vãi, lại mưa à&quot; hay là &quot; mưa lâu vậy khi nào mới tạnh&quot; chứ bao giờ có &quot; mưa rồi, vui quá &quot; đâu.&lt;/p&gt;

&lt;p&gt;- Khi yêu người ta sẽ ngại nên gửi gắm lời yêu thương qua những câu chửi. Thương cho chửi cho trù mà.&lt;/p&gt;

&lt;p&gt;- Điêu thật, tin thì chắc không tin nổi đâu chi bằng nói những gì ngươi cảm nhận về ta đi. Nghìn lời giả dối không bằng một cảm xúc chân thật.&lt;/p&gt;

&lt;p&gt;- Uhm được. Khi còn nhỏ vô lo vô nghĩ, tôi thích nghe những âm thanh tí tách khi những hạt mưa rơi xuống đất hay trên nóc nhà tạo nên một bản nhạc nhẹ nhàng lắng đọng. Khi đó, tôi cũng rất thích đi với em, từng hạt mưa rơi trên người như cuốn phăng mọi mệt mỏi. Tôi thích tiếng mưa tầm tã đủ để thành điệu ru khi tôi vùi đầu vào chăn ấm, ngủ một giấc cho đến sáng, và tuyệt hơn nữa là khi thức dậy trời vẫn còn mưa. Tôi thích hơi lạnh từ mưa tô điểm cho bầu không khí ấm áp quây quần bên gia đình.&lt;/p&gt;

&lt;p&gt;- Ta cũng thích ngươi khi nhỏ hơn, những ngày đó ngươi không chửi rủa ta. Lần nào ta đến cũng đòi ra chơi với ta mặc dù bị mẹ cấm hay ngày hôm sau lăn đùng ra ốm. Đã yếu mà còn đòi ra mưa.&lt;/p&gt;

&lt;p&gt;- Vậy là đủ chứng minh chưa ?.&lt;/p&gt;

&lt;p&gt;- Đó là lúc nhỏ, ngươi có biết gì đâu. Và những gì ngươi nói đều do ta đem đến chứ không phải cảm nhận về ta. Lớn lên thì mỗi lần ta đến, ngươi lại chửi liên tục không trật nhịp nào cho đến khi ta đi vẫn còn dư âm.&lt;/p&gt;

&lt;p&gt;- Khi lớn, tôi thích ngắm nhìn hơn là đứng trong em. Vì tắm mưa thì không cuốn phăng mọi ưu phiền được nữa và nhờ đó tôi mới thấy được em rõ hơn. Em trong con mắt của kẻ đa tình đa sầu luôn là dáng dấp của nỗi buồn, hình dạng của của cô đơn và hương vị của những hoài niệm kí ức. Nhưng hơn mọi thứ, em đem đến cho tôi sự thú vị và một khoảng lặng. Khi em vừa đến, đường phố nhộn nhịp hơn, người lớn thì vội vã, các bạn nữ sinh thì hối hả. Vậy mà mấy thằng nhóc lại vui mừng chạy ra đường tắm mưa, hò hét ầm ĩ. Một lúc sau đường vắng hơn, chỉ còn lại vài chiếc xe lầm lũi chạy đua với những hạt nước nặng trĩu. Những lúc này thích nhất là đứng dưới hiên nhà đứng dưới bầu trời đen âm ỉ, ngắm nhìn những giọt mưa tưới mát cho vạn vật, cảm nhận được làn hơi mát lạnh và nhẹ nhàng mở ra căn phòng của những ký ức. Tưởng đã khóa kín cửa nhưng em lại khơi gợi cho tôi những hoài niệm dần mơ hồ. Khi bên cạnh chỉ còn mưa, tôi chẳng còn sức để giữ lại những suy nghĩ cho riêng mình. Trong mưa, con phố chợt thênh thang hơn, con đường bỗng dài và hiu quạnh nhưng lòng người thì bé lại gói gọn chỉ bằng một nỗi nhớ. Chả sai khi nói &quot; người buồn cảnh có vui đâu bao giờ &quot;. Dường như mưa trở nên nặng nề hơn khi tâm tư ta nặng trĩu tâm trạng.&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;
 &lt;img src=&quot;/assets/img/blog/title/tam-su-cung-mua.png&quot; alt=&quot;Tamsu&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
Tôi thở dài.&lt;/p&gt;
&lt;p&gt;- Em lần này đến sao vô tình đến thế để tôi chìm vào những cảm xúc bất tận và dòng suy nghĩ miên man. &lt;/p&gt;

&lt;p&gt;Mưa mãi rơi, người ngơ ngẩn mãi nơi đây. Mưa nhỏ dần, nhỏ dần rồi tạnh hẳn. Cây cối rùng mình hắt những giọt nước còn đọng lại trên lá cành để đón chào những tia nắng rực rỡ. Không gian thật thoáng đãng. Tôi thẫn thờ còn chưa kịp hỏi.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p style=&quot;font-size:16px&quot;&gt; Sài Gòn nóng vậy cũng đã đổ mưa. Em khó tính như vậy khi nào mới đổ tôi.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
      </item>
    
      <item>
        <title>[Kafka for Dummies - Part 1] Introduction</title>
        <link>http://0.0.0.0:4000/work/2019/03/29/p1-introduction-apache-kafka.html</link>
        <pubDate>Fri, 29 Mar 2019 00:00:00 -0500</pubDate>
        <author></author>
        <description>&lt;p&gt;Big Data is way too hotter than you think. It’s gonna get hotter and show no signs of stopping. One of the biggest challenges associated with Big Data is, turn data into meaningful insights. However before diving into that part, the data has to be first collected then is transfered impeccably in purpose of the availability to the end-users. Hadoop, Spark, Scala, ElasticSearch, … are types of platforms, frameworks and technologies which have emerged to help us handle the ever-growing amount of data over the internet. Among them, Kafka plays an important role. Kafka’s not hard to learn but it has many remarkable theories and concepts. That’s where this series comes in. To those who know nothing about Kafka or wanna revise quickly, my goal is to supply all the basics you need. At the end of the road, you will get a concise overview and apply Kafka easily.&lt;/p&gt;

&lt;hr /&gt;
&lt;h3&gt; What is Kafka ?&lt;/h3&gt;
&lt;p&gt;It is a distributed publish-subscribe messaging system that specifically designed for the high-speed, real-time, scalable and low-latency information processing.&lt;/p&gt;

&lt;p&gt;Apache Kafka was originally developed by LinkedIn, and was subsequently open sourced in early 2011. Being open source means that It is essentially free to use and has a large community who contributes towards updates and new features.&lt;/p&gt;

&lt;hr /&gt;
&lt;h3&gt; How does Kafka start?&lt;/h3&gt;
&lt;p&gt;&lt;u&gt;&lt;em&gt;It looks simple at first:&lt;/em&gt;&lt;/u&gt;  When we have only one data source and one target system.
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;/assets/img/blog/content/ds1.png&quot; alt=&quot;Simple process&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;
&lt;u&gt;&lt;em&gt;Things now became really complicated:&lt;/em&gt;&lt;/u&gt;&lt;/p&gt;
&lt;p&gt; Because of new marketing stragety, We need to collect more kind of data and supply for more target systems. It turns out that your project has 4 data sources and 4 target systems. Then we have 16 integrations because they all have to exchange data with one another:&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;
 &lt;img src=&quot;/assets/img/blog/content/ds2.png&quot; alt=&quot;Complicated process&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;
But somewhere down the road, you realize that each integration generate some difficulties:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;- Protocol: How the data is transported ( TCP, REST, ....)&lt;/li&gt;
    &lt;li&gt;- Data format : How the data is parsed and extracted ( JSON, CSV, Binary, ... )&lt;/li&gt;
    &lt;li&gt;- Data schema &amp;amp; evolution : How the data is formed and may change in the future.&lt;/li&gt;
    &lt;li&gt;- Each source system will increased load from the connection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;strong&gt;Then, Kafka comes in like the Buddha to solves all the bottlenecks.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It allows to decouple your entry data streams and systems . Now, the source system will push your data into Kafka. While, the target system will source data straight from Kafka. With Kafka’s help, what it enables is really really nice .&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;
 &lt;img src=&quot;/assets/img/blog/content/ds3.png&quot; alt=&quot;Complicated process&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;We can have any data sources you can think like SERVER LOG, USER BEHAVIOR, PAYMENT TRANSACTIONS, … . After that, when data is in Kafka, you could put it into any target systems such as DATABASE, METRIC, AUDIT, ANALYTICS, … (above image)&lt;/p&gt;

&lt;hr /&gt;
&lt;h3&gt; Why would we need to use Apache Kafka ?&lt;/h3&gt;
&lt;p&gt;&lt;u&gt;Considering its standout:&lt;u&gt;&lt;/u&gt;&lt;/u&gt;&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;-  Distributed, resilient architecture, fault tolerant.&lt;/li&gt;
    &lt;li&gt;-  Horizontal scalability: scale to 100s of brokers and scale to millions of messages per second.&lt;/li&gt;
    &lt;li&gt;-  High performance (the latency to exchange data from one system to another is usually less than 10ms) and It's realtime.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
&lt;u&gt;And its use cases: &lt;/u&gt;&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;-  Messaging System.&lt;/li&gt;
    &lt;li&gt;-  Activity Tracking&lt;/li&gt;
    &lt;li&gt;-  Gather metrics from many different locations ( IoT devices )&lt;/li&gt;
    &lt;li&gt;-  Application Logs gathering&lt;/li&gt;
    &lt;li&gt;-  Stream processing ( with the Kafka Stream API or Spark for example )&lt;/li&gt;
    &lt;li&gt;-  De-coupling of system dependencies&lt;/li&gt;
    &lt;li&gt;-  Integration with Spark, Flink, Storm, Hadoop and many other Big Data technologies.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;h3&gt; Can I believe you ? &lt;/h3&gt;
&lt;p&gt;Don’t believe me. You can believe 2000 plus firms and 35% of the Fortune 500 that uses Kafka as their backbone.
&lt;br /&gt;
&lt;u&gt;Concrete example:&lt;/u&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;- Netflix uses Kafka to apply recommendations in real-time while you're watching TV shows.&lt;/li&gt;
&lt;li&gt;- Uber uses Kafka to gather user, taxi and trip data in real-time to compute and forecast demand, and compute surge pricing in real-time.&lt;/li&gt;
&lt;li&gt;- Linkedin uses Kafka to prevent spam, collect user interactions to make better connection recommendations in real-time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;b&gt;Rememeber that Kafka is only used as transportation mechanism! &lt;/b&gt;&lt;/p&gt;

</description>
      </item>
    

  </channel>
</rss>
